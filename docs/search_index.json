[
["index.html", "POLS0008: Introduction to Quantitative Research Methods Welcome", " POLS0008: Introduction to Quantitative Research Methods Justin van Dijk1, Stephen Jivraj2 2021-08-03 Welcome Welcome to POLS0008: Introduction to Quantitative Research Methods, one of the first year core module for students enrolled on Q-Step programmes and a second year methods option in BSc Philosophy, Politics and Economics. Before we start, please take a moment to read through the information below and watch the course introduction video. The video should answer any questions you may have with regard to the structure of the course, where to find your course materials, and what options you have when you have questions. Course Introduction [Lecture slides] [Watch on MS stream] Moodle All important information and communication in relation to this module will be provided on Moodle. Even though for the first 4 weeks all short lecture videos and practical materials will be hosted on this webpage, do check on Moodle regularly to see if there are any updates or important messages. Structure Although there may be some slight variation from week to week, the course is generally structured by several short lecture videos, reading material, a computer practical, a seminar task that you need to do in preparation of the live seminar, and a live seminar. Each week, all content for that week will be made available online by Monday morning. All live seminars take place on Thursday morning. This means that you have 3 days to go through all the materials and conduct your seminar task before it is discussed in the live seminar. Assessment This module is assessed by one 3,000 word essay (counting 100% towards your final mark for this course) based on secondary analysis of survey data. The assessment will be introduced by Dr Stephen Jivraj and more details will follow in later weeks. Technical support We do not offer any technical support. If you have any technical questions or encounter technical problems, you will have to take this up with the IT Service Desk. Similarly, for questions related to the organisation of the course (e.g. to which seminar group your get assigned to), you will have to direct your queries to the student office of your Department. Office hours Office hours with Dr Justin van Dijk (Tuesdays between 14h00 and 15h00) can be booked here. Office hours with Dr Stephen Jivraj (Tuesdays between 09h45 and 10h45) can be booked here. Department of Geography, https://www.mappingdutchman.com/↩︎ Institute of Epidemiology and Health Care, https://www.ucl.ac.uk/q-step/stephen-jivraj↩︎ "],
["understanding-data.html", "1 Understanding data 1.1 Introduction 1.2 Data and statistics 1.3 R for data analysis 1.4 R console 1.5 R script 1.6 Seminar 1.7 Before you leave", " 1 Understanding data 1.1 Introduction Welcome to your first week of Introduction to Quantitative Research Methods. This week we will focus on understanding data. We will also introduce you to some basic statistical terminology. Lastly, we will introduce you to the software tools that we will be using throughout this course: R and RStudio. Note Before you continue, make sure you have read through the details on the welcome page of this handbook and have watched the course introduction video. This week is structured by 5 short videos, practical material that you need to work through in preparation for Thursday’s seminar, and a seminar task that you need to do in preparation for Thursday’s seminar. Let’s get started. Video: Introduction W01 [Lecture slides] [Watch on MS stream] 1.1.1 Reading list Please find the reading list for this week below. We strongly recommend that you read the core reading material before you continue with the rest of this week’s material. Core reading Lane et al., 2003, Chapter 1: Introduction. In: Lane et al., 2003, Introduction to Statistics. Houston, Texas: Rice University. [Link] Supplementary reading Diez et al., 2019, Chapter 1: Introduction to data. In: Diez et al., 2019, OpenIntro Statistics. Fourth Edition. Boston, Massachusetts: OpenIntro. [Link] 1.1.2 Q&amp;A session This week there will be a live Q&amp;A session on Tuesday, January 12, 2020 @ 11h00 (GMT). The session will be hosted on Zoom [Link]. For security reasons, the meeting password for this Q&amp;A session can be found on Moodle on the main page: POLS0008 - Q&amp;A - Tuesday 11:00. 1.2 Data and statistics Some of you may wonder why it is necessary to take a course on data and statistics in the first place? Well, there are several compelling reasons to have a (basic) knowledge of data and statistics: it will help you to understand and critically engage with academic articles; it will help you critically assess statistics used in the media, government reports, etc.; it will help you write a dissertation based on secondary analysis; it will help you write your own work convincingly. Further to this, data skills are in high demand by employers both in the public and private sectors. Video: Data and statistics [Lecture slides] [Watch on MS stream] 1.3 R for data analysis Arguably the easiest way to start learning about data and statistics is by getting our hands dirty. So, before we will introduce you to some statistical terminology, we will have a look at one of the software tools with which we will be working this semester: R. R is a free software environment for statistical computing and graphics. It is extremely powerful and as such is now widely used for academic research as well as in the commercial sector. Ever wondered what tool is used to create those excellent coronavirus visualisations in the Financial Times? R’s great strength is that it is open-source, can be used on all major computer operating systems and is free for anyone to use. Because of this, it is has rapidly become one of the statistical languages of choice for many academics. Moreover, it has a large and active user community with people constantly contributing new packages to carry out all manner of statistical and graphical analysis. Unlike software programmes such as Microsoft Excel or SPSS, within a coding environment the user has to type commands to get it to execute tasks such as loading in a data set or performing a calculation. The biggest advantage of this approach is that you can build up a document, or script, that provides a record of what you have done, which in turn enables the straightforward repetition of tasks. Graphics can be easily modified and tweaked by making slight changes to the script or by scrolling through past commands and making quick edits. Unfortunately, command-line computing can also be off-putting at first. It is easy to make mistakes that are not always obvious to detect. Nevertheless, there are good reasons to stick with R. These include: It’s broadly intuitive with a strong focus on publishable-quality graphics. It’s ‘intelligent’ and offers in-built good practice – it tends to stick to statistical conventions and present data in sensible ways. It’s free, cross-platform, customisable and extendable with a whole swathe of libraries (‘add ons’) including those for discrete choice, multilevel and longitudinal regression, and mapping, spatial statistics, spatial regression, and geostatistics. It is well respected and used at the world’s largest technology companies (including Google, Microsoft and Facebook, and at hundreds of other companies). It offers a transferable skill that shows to potential employers experience both of statistics and of computing. The intention of the practical elements of this week is to provide a thorough introduction to R to get you started: The basic programming principles behind R. Loading in data from csv files and subsetting it into smaller chunks. Calculating a number of statistics for data exploration and checking. Creating basic and more complex plots in order to visualise the distributions values within a data set. R has a steep learning curve, but the benefits of using it are well worth the effort. Take your time and think through every piece of code you type in. The best way to learn R is to take the basic code provided in tutorials and experiment with changing parameters - such as the colour of points in a graph - to really get ‘under the hood’ of the software. Take lots of notes as you go along and if you are getting really frustrated take a break! Video: R for data analysis [Lecture slides] [Watch on MS stream] POLS0008 forum If you encounter a problem during the course, e.g. something is unclear or you are stuck with your R code, you can post your question on the POLS0008 Forum. If you do not have questions yourself, do check the forum regularly as you may be able to help fellow students. Of course, the answers are moderated by the module tutors and the brilliant teaching support staff. Some tips about how to get the best out of the forum: Be efficient, but also be polite. It just makes it a nicer read for all of us if you start with a greeting and end on a thanks, etc.! Be clear in the subject about what you are asking about. Topics named “Final Task” and “Same Problem”, for example, will get confusing very fast. We want the forum to be a lasting record of the module and there maybe something on there you want to refer back to so having descriptive subjects helps. For example “Boxplot does not have any whiskers” or “Unable to load in csv file” is better. Concisely outline the problem and also the steps you have taken to solve it. Explain what you are trying to do and why. This is really helpful for us to troubleshoot. As we will be using a programming language during the computer tutorials, the mistake you made might have happened a few lines of code before the one that is showing the error. We won’t know this without some extra context. Include the R code - a screenshot is fine but show the whole screen: there can be some useful clues in the console and objects list that we won’t see if you are showing only one line of code. If we solve a problem acknowledge this with a reply! How will we know otherwise? If you think you know the answer to someone’s question help them out! If you are having a similar issue post to the forum - including what you have done to try and fix it. 1.4 R console You can download and install R on your laptop but for the purposes of this course we would like you to use the version hosted on the UCL servers so that everyone participating in the course has access to the same version of the software. Open a web browser and navigate to: https://rstudio.data-science.rc.ucl.ac.uk/ Log in with your usual UCL username and password. You should see the RStudio interface appear. If it is the first time you log on to RStudio server you may only see the RStudio interface appear once you have clicked on the start a new session button.s Note RStudio server will only work with an active VPN connection that links your personal computer into UCL’s network. Students in mainland may want to use UCL China Connect. Students that use a Mac computer that is running on the latest version of MacOS (MacOS Big Sur), are advised to use Desktop@UCL as the Cisco AnyConnect VPN application may not work. If you are completely unable to access the server (e.g. your browser displays a This site can’t be reached message), it means that your VPN connection is not working correctly. Please ensure that your VPN is working correctly or use Desktop@UCL Anywhere instead. Figure 1.1: The RStudio interface. If you managed to log onto RStudio server: brilliant, we are ready to go. At its absolute simplest R is a calculator, so let’s try adding some numbers by typing in the console window and hitting enter to execute the code: 4 + 10 ## [1] 14 You will notices that in the command line window, it will give you an answer directly (i.e. 14). These outputs of the command line window are shown as ## throughout this handbook and you do not need to type anything into the command line that follows ## (because it simply shows the result of a command!). Note Anything that appears as red in the command line means it is an error (or a warning) so you will likely need to correct your code. If you see a &gt; on the left it means you can type in your next line, a + means that you haven’t finished the previous line of code. As will become clear, + signs often appear if you don’t close brackets or you did not properly finish your command in a way that R expected. Rather than using numbers and values, it is often easier to assign numbers (or groups of them) a memorable name for easy reference later. In R terminology this is called creating an object and this is really important. Let’s try this: a &lt;- 4 b &lt;- 10 The &lt;- symbol is used to assign the value to the name, in the above we assigned the integer 4 to an object with the name a. Similarly, we assigned the integer 10 to an object with the name b To see what each object contains you can just type print(name of your object), so in our case: print(a) ## [1] 4 print(b) ## [1] 10 This may look trivial, but in fact it is extremely powerful as objects can be treated in the same way as the numbers they contain. For instance: a*b ## [1] 40 Or even used to create new objects: ab &lt;- a*b print(ab) ## [1] 40 You can generate a list of objects that are currently active using the ls() command. R stores objects in your computer’s RAM so they can be processed quickly. Without saving (we will come onto this below) these objects will be lost if you close R (or it crashes). ls() ## [1] &quot;a&quot; &quot;ab&quot; &quot;b&quot; You may wish to delete an object. This can be done using rm() with the name of the object in the brackets. For example: rm(ab) To confirm that your command has worked, just run the ls() command again: ls() ## [1] &quot;a&quot; &quot;b&quot; Note Remember that if you have any questions with your R code and you are stuck that you can post a question on the POLS0008 Forum! Let’s now take a short break from RStudio and have a look at some theory: the video below will introduce you to some essential statistical terminology. Video: Statistical terminology [Lecture slides] [Watch on MS stream] Now we now a little more about different types of variables and levels of measurement, we can go back to RStudio. Until now our objects have been extremely simple integers (i.e. whole numbers), but the real power of R comes when we can begin to execute functions on objects. Let’s have a closer look at functions by firstly building a more complex object through the c() function. The c in the c() function means concatenate and essentially groups things together. Let’s create an object that contains the birth years of the six main characters in the popular American television sitcom Friends. friends_dob &lt;- c(1969,1967,1970,1968,1968,1967) Let’s check the results. print(friends_dob) ## [1] 1969 1967 1970 1968 1968 1967 Now, we can execute some statistical functions on this object such as calculating the mean() value, the median() value, and the range() of the data. mean(friends_dob) ## [1] 1968.167 median(friends_dob) ## [1] 1968 range(friends_dob) ## [1] 1967 1970 Note In next week’s material we will dive a little deeper into these statistical functions, for now, however, we only want you to know how to execute a function. If at this stage you are not entirely sure on what what exactly is a range, median, or mean that is perfectly fine and you should not worry about it just yet. All functions need a series of arguments to be passed to them in order to work. These arguments are typed within the brackets and typically comprise the name of the object (in the examples above its the friends_dob) that contains the data followed by some parameters. The exact parameters required are listed in the functions help files. To find the help file for the function type ? followed by the function name, for example: ?mean All helpfiles will have a usage heading detailing the parameters required. In the case of the mean you can see it simply says mean(x, ...). In function helpfiles x will always refer to the object the function requires and, in the case of the mean, the ... refers to some optional arguments that we don’t need to worry about. Note When you are new to R the help files can seem pretty impenetrable (because they often are!). Up until relatively recently these were all people had to go on, but in recent years R has really taken off and so there are plenty of places to find help and tips. Google is the best tool to use. When people are having problems they tend to post examples of their code online and then the R community will correct it. One of the best ways to solve a problem is to paste their correct code into your R command line window and then gradually change it for your data and purposes. The structure of the friends_dob object - essentially a group of numbers (integers!) - is known as a vector object in R. To build more complex objects that, for example, resemble a spreadsheet with multiple columns of data, it is possible to create a class of objects known as a data frame. This is probably the most commonly used class of object in R. We can create one here by combining two vectors. friends_characters &lt;- c(&#39;Monica&#39;,&#39;Ross&#39;,&#39;Rachel&#39;,&#39;Joey&#39;,&#39;Chandler&#39;,&#39;Phoebe&#39;) friends &lt;- data.frame(friends_characters, friends_dob) If you type print(friends) you will see our newly created data frame that consists of the first vector object (date of birth) and the second vector objects (names of characters). print(friends) ## friends_characters friends_dob ## 1 Monica 1969 ## 2 Ross 1967 ## 3 Rachel 1970 ## 4 Joey 1968 ## 5 Chandler 1968 ## 6 Phoebe 1967 Tips R is case sensitive so you need to make sure that you capitalise everything correctly if required. The spaces between the words don’t matter but the positions of the commas and brackets do. Remember, if you find the prompt, &gt;, is replaced with a + it is because the command is incomplete. If necessary, hit the escape (esc) key and try again. It is important to come up with good names for your objects. In the case of the friends_dob object we used a underscore _ to separate the words. It is good practice to keep the object names as short as posssible so we could have gone for FriendsDob or f_dob. Be aware: you cannot start an object name with a number! If you press the up arrow in the command line you will be able to edit the previous lines of code you inputted. Recap In this section you have: Entered your first commands into the R command line interface. Created objects in R. Created a vector of values (the friends_dob object). Executed some simple R functions. Created a data frame (called friends). 1.5 R script In the previous section, R may have seemed fairly labour-intensive. We had to enter all our data manually and each line of code had to be written into the command line. Fortunately this isn’t routinely the case. In RStudio look to the top left corner and you will see a plus symbol, click on it and select R Script. Figure 1.2: Opening a new script in RStudio. This should give you a blank document that looks a bit like the command line. The difference is that anything you type here can be saved as a script and re-run at a later date. Figure 1.3: The RStudio interface with a new script. When writing a script it is important to keep notes about what each step is doing. To do this the hash (#) symbol is put before any code. This comments out that particular line so that R ignores it when the script is run. Type the following into the scripting window: # first attempt at creating a script Some.Data &lt;- data.frame(0:10,20:30) # inspect the result print(Some.Data) Questions Without running these lines of code, what do you expect to happen? Do you understand what these simple line of codes do? In the scripting window if you highlight all the code you have written and press the Run button on the top on the scripting window you will see that the code is sent to the command line and the text on the line after the # is ignored. From now on you should type your code in the scripting window and then use the Run button to execute it. If you have an error then edit the line in the script and hit run again. Try it: # first attempt at creating a script Some.Data &lt;- data.frame(0:10,20:30) print(Some.Data) ## X0.10 X20.30 ## 1 0 20 ## 2 1 21 ## 3 2 22 ## 4 3 23 ## 5 4 24 ## 6 5 25 ## 7 6 26 ## 8 7 27 ## 9 8 28 ## 10 9 29 ## 11 10 30 The My.Data object is a data frame in need of some sensible column headings. You can add these by typing: # add column names names(Some.Data)&lt;- c(&#39;x&#39;,&#39;y&#39;) # print the object to check names were added successfully print(Some.Data) ## x y ## 1 0 20 ## 2 1 21 ## 3 2 22 ## 4 3 23 ## 5 4 24 ## 6 5 25 ## 7 6 26 ## 8 7 27 ## 9 8 28 ## 10 9 29 ## 11 10 30 Until now we have generated the data used in the examples above. One of R’s great strengths is its ability to load in data from almost any file format. Comma Separated Value (csv) files are our preferred choice. These can be thought of as stripped down Excel spreadsheets. They are an extremely simple format so they are easily machine readable and can therefore be easily read in and written out of R. As some of you may have never heard of a csv file before, in the video below we will look at csv files in a little more detail. Video: csv files [Lecture slides] [Watch on MS stream] Working Directory Since we are now reading and writing files it is good practice to tell R what your working directory is. Your working directory is the folder on the computer where you wish to store the data files you are working with. You can create a folder called POLS0008, for example. If you are using RStudio, on the lower right of the screen is a window with a Files tab. If you click on this tab you can then navigate to the folder you wish to use. You can then click on the More button and then Set as Working Directory. You should then see some code similar to the below appear in the command line. It is also possible to type the code in manually. # set the working directory path to the folder you wish to use # you may need to create the folder first if it doesn&#39;t exist setwd(&#39;~/POLS0008&#39;) # note the single / (\\\\ will also work) Note Please ensure that folder names and file names do not contain spaces or special characters such as * . \" / \\ [ ] : ; | = , &lt; ? &gt; &amp; $ # ! ' { } ( ). Different operating systems and programming languages deal differently with spaces and special characters and as such including these in your folder names and file names can cause many problems and unexpected errors. As an alternative to using white space you can use an underscore _ if you like. Once the working directory is setup it is then possible to load in a csv file. We are going to load a data set that has been saved in the working directory we just set that shows London’s historic population for each of its Boroughs. You can download the csv file below. The csv file is also available on Moodle in the data sets for practicals folder. File download File Type Link Borough Population London csv Download Once downloaded to your own computer, this file will then need to be uploaded into RStudio. To do this click on the Upload button in the files area of the screen. Select the csv file you just downloaded and press OK. We can then type the following to locate and load in the file we need. # load csv file from working directory London.Pop &lt;- read.csv(&#39;census-historic-population-borough.csv&#39;) To view the object type:s print(London.Pop) ## Area.Code Area.Name Persons.1801 Persons.1811 Persons.1821 ## 1 00AA City of London 129000 121000 125000 ## Persons.1831 Persons.1841 Persons.1851 Persons.1861 Persons.1871 ## 1 123000 124000 128000 112000 75000 ## Persons.1881 Persons.1891 Persons.1901 Persons.1911 Persons.1921 ## 1 51000 38000 27000 20000 14000 ## Persons.1931 Persons.1939 Persons.1951 Persons.1961 Persons.1971 ## 1 11000 9000 5000 4767 4000 ## Persons.1981 Persons.1991 Persons.2001 Persons.2011 Borough.Type ## 1 5864 4230 7181 7375 1 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 32 rows ] Or if you only want to see the top 10 or bottom 10 rows you can use the head() and tail() functions. These are particularly useful if you have large data sets! # view first 10 rows head(London.Pop) ## Area.Code Area.Name Persons.1801 Persons.1811 Persons.1821 ## 1 00AA City of London 129000 121000 125000 ## Persons.1831 Persons.1841 Persons.1851 Persons.1861 Persons.1871 ## 1 123000 124000 128000 112000 75000 ## Persons.1881 Persons.1891 Persons.1901 Persons.1911 Persons.1921 ## 1 51000 38000 27000 20000 14000 ## Persons.1931 Persons.1939 Persons.1951 Persons.1961 Persons.1971 ## 1 11000 9000 5000 4767 4000 ## Persons.1981 Persons.1991 Persons.2001 Persons.2011 Borough.Type ## 1 5864 4230 7181 7375 1 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 5 rows ] # view bottom 10 rows tail(London.Pop) ## Area.Code Area.Name Persons.1801 Persons.1811 Persons.1821 Persons.1831 ## 28 00BE Southwark 116000 139000 175000 207000 ## Persons.1841 Persons.1851 Persons.1861 Persons.1871 Persons.1881 ## 28 243000 292000 346000 407000 514000 ## Persons.1891 Persons.1901 Persons.1911 Persons.1921 Persons.1931 ## 28 572000 596000 579000 571000 535000 ## Persons.1939 Persons.1951 Persons.1961 Persons.1971 Persons.1981 ## 28 456000 338000 313413 262000 211858 ## Persons.1991 Persons.2001 Persons.2011 Borough.Type ## 28 198916 244867 288283 1 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 5 rows ] Note Depending on the type of object the exact number of lines displayed through head() and tail() may differ. If you want to have precise control over the output and specify how many rows will be printed, you can do this by passing an integer as second argument to either of these functions. For instance, head(London.Pop, n=10) or tail(London.Pop, n=10). To learn a bit more about the file you have loaded, R has a number of useful functions. We can use these to find out how many columns (variables) and rows (cases) the data frame (data set) contains. # get the number of columns ncol(London.Pop) ## [1] 25 # get the number of rows nrow(London.Pop) ## [1] 33 # list the column headings names(London.Pop) ## [1] &quot;Area.Code&quot; &quot;Area.Name&quot; &quot;Persons.1801&quot; &quot;Persons.1811&quot; ## [5] &quot;Persons.1821&quot; &quot;Persons.1831&quot; &quot;Persons.1841&quot; &quot;Persons.1851&quot; ## [9] &quot;Persons.1861&quot; &quot;Persons.1871&quot; &quot;Persons.1881&quot; &quot;Persons.1891&quot; ## [13] &quot;Persons.1901&quot; &quot;Persons.1911&quot; &quot;Persons.1921&quot; &quot;Persons.1931&quot; ## [17] &quot;Persons.1939&quot; &quot;Persons.1951&quot; &quot;Persons.1961&quot; &quot;Persons.1971&quot; ## [21] &quot;Persons.1981&quot; &quot;Persons.1991&quot; &quot;Persons.2001&quot; &quot;Persons.2011&quot; ## [25] &quot;Borough.Type&quot; Given the number of columns in the pop data frame, subsetting by selecting on the columns of interest would make it easier to handle. In R there are two was of doing this. The first uses the $ symbol to select columns by name and then create a new data frame object. # select the columns containing the Borough names and the 2011 population London.Pop.2011 &lt;- data.frame(London.Pop$Area.Name, London.Pop$Persons.2011) # inspect the results head(London.Pop.2011) ## London.Pop.Area.Name London.Pop.Persons.2011 ## 1 City of London 7375 ## 2 Barking and Dagenham 185911 ## 3 Barnet 356386 ## 4 Bexley 231997 ## 5 Brent 311215 ## 6 Bromley 309392 A second approach to selecting particular data is to use [Row, Column] and ‘slice’ the data frame. For instance: # select the 1st row of the 2nd column London.Pop[1,2] ## [1] City of London ## 33 Levels: Barking and Dagenham Barnet Bexley Brent Bromley ... Westminster # select the first 5 rows of the 1st column London.Pop[1:5,1] ## [1] 00AA 00AB 00AC 00AD 00AE ## 33 Levels: 00AA 00AB 00AC 00AD 00AE 00AF 00AG 00AH 00AJ 00AK 00AL ... 00BK # select the first 5 rows of columns 8 to 11 London.Pop[1:5,8:11] ## Persons.1851 Persons.1861 Persons.1871 Persons.1881 ## 1 128000 112000 75000 51000 ## 2 8000 8000 10000 13000 ## 3 15000 20000 29000 41000 ## 4 12000 15000 22000 29000 ## 5 5000 6000 19000 31000 # assign the previous selection to a new object London.Subset &lt;- London.Pop[1:5,8:11] In the code snippet, note how the colon : is used to specify a range of values. We used the same technique to create the Some.Data object above. The ability to select particular columns means we can see how the population of London’s Boroughs have changed over the past century by subtracting two columns from one another. # within the brackets you can add additional columns to the data frame # as long as their separated by commas Pop.Change &lt;- data.frame(London.Pop$Area.Name, London.Pop$Persons.2011 - London.Pop$Persons.1911) If you type head(PopChange) you will see that the population change column (created to the right of the comma above) has a very long name. This can be changed using the names() command in the same way as we did this for our Some.Data object. names(Pop.Change) &lt;- c(&#39;Borough&#39;, &#39;Change_1911_2011&#39;) Since we have done some new analysis and created additional information it would be good to save the PopChange object to our working directory as a new csv file. This is done using the code below. Within the brackets we put the name of the R object we wish to save on the left of the comma and the file name on the right of the comma (this needs to be in inverted commas). Remember to put .csv after since this is the file format we are saving in. write.csv(Pop.Change, &#39;Population_Change_1911_2011.csv&#39;) Recap In this section you have learnt how to: Create an R script. Load a csv into R, perform some analysis, and write out a new csv file to your working directory. Subset R data frames by name and also column and/or row number. 1.6 Seminar Please find the seminar task and seminar questions for this week’s seminar below. Note Please make sure that you have executed the seminar task and have answered the seminar questions before the seminar! Seminar task Create a csv file that contains the following columns: The names of the London Boroughs. Population change between 1811 and 1911. Population change between 1911 and 1961. Population change between 1961 and 2011. Seminar questions Answer the following questions: Which Boroughs had the fastest growth between 1911 and 1961, and which had the slowest? You may have noticed that there is an additional column in the pop data frame called Borough-Type. This indicates if a Borough is in inner (1) or outer (2) London. Is this variable ordinal or nominal? Seminar link Seminars for all groups take place on Thursday morning. You can find the Zoom link to your seminar group on Moodle in the Seminar links folder. 1.7 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "],
["examining-data-i.html", "2 Examining data I 2.1 Introduction 2.2 Measures of central tendency 2.3 Simple plots 2.4 Measures of dispersion 2.5 Seminar 2.6 Before you leave", " 2 Examining data I 2.1 Introduction Welcome to your second week of Introduction to Quantitative Research Methods. This week we will focus on examining data using measures of central tendency and measures of dispersion. These measures are collectively known as descriptive statistics. We will also talk about some basic data visualisation. Also, as by now everyone should be up and running with R, we will apply some of these descriptive measures onto some data. Nice! This week is structured by 3 short videos, practical material that you need to work through in preparation for Thursday’s seminar, and a seminar task that you need to do in preparation for Thursday’s seminar. Let’s get to it. Video: Introduction W02 [Lecture slides] [Watch on MS stream] 2.1.1 Reading list Please find the reading list for this week below. We strongly recommend that you read the core reading material before you continue with the rest of this week’s material. Core reading Lane et al., 2003, Chapter 3: Summarizing Distributions. In: Lane et al., 2003, Introduction to Statistics. Houston, Texas: Rice University. [Link] Supplementary reading Diez et al., 2019, Chapter 2: Summarizing data. In: Diez et al., 2019, OpenIntro Statistics. Fourth Edition. Boston, Massachusetts: OpenIntro. [Link] 2.1.2 Q&amp;A session This week there is NO live Q&amp;A session scheduled. Please post any questions you have on the POLS0008 Forum or ask them to your seminar leader during your live seminar on Thursday. 2.2 Measures of central tendency Any research project involving quantitative data should start with an exploration and examination of the available data sets. This applies both to data that you have collected yourself and data that you have acquired in a different way, e.g. through downloading official UK Census and labour market statistics. The set of techniques that is used to examine your data in first instance is called descriptive statistics. Descriptive statistics are used to describe the basic features of your data set and provide simple summaries about your data. Together with simple visual analysis, they form the basis of virtually every quantitative data analysis. Video: Measures of central tendency [Lecture slides] [Watch on MS stream] For this tutorial we will initially continue to use the London.Pop object that we created during last week’s tutorial. You may still have it loaded into your R workspace if your RStudio Server session is still active. To check if you do, you can use the ls() command to get a list of all objects that are available in your RStudio session. Type this into the command line and see if London.Pop is printed. If not you can simply reload it: # set the working directory path to the folder you wish to use # this would be the folder that you created during last week&#39;s practical setwd(&#39;~/POLS0008&#39;) # note the single / (\\\\ will also work) If you struggle with setting up your working directory and you need a reminder, have a look at how we did this last week! # load csv file from working directory London.Pop &lt;- read.csv(&#39;census-historic-population-borough.csv&#39;) Use the head(), or View(), function to remind yourself of the structure of the London population data frame. You should see 25 columns of data. Questions What is the difference between using head() and View() to inspect your data? Can you combine the functions View() and head() to browse only through a few lines of your data? The mean() and median() were some of the first R functions we used last week to describe our Friends data frame Now we know a little more about these measures of central tendency, we can also apply them on our London.Pop data set. Let’s do this by focusing on London’s population in 2011. # select the relevant columns London.Pop2011 &lt;- London.Pop[,c(1:2,24)] Questions Do you remember what the c() function does? Why do we need to use the c() in this case? Instead of using the [ , ] syntax to slice our data frame, how can we create the same London.Pop2011 object by using the $ syntax? Now we can calculate our measures of central tendency using R’s built-in functions for the median and the mean. # calculate the median of the 2011 population variable median(London.Pop2011$Persons.2011) ## [1] 254096 # calculate the mean of the 2011 population variable mean(London.Pop2011$Persons.2011) ## [1] 247695.2 Questions How do you explain that the median is larger than the mean for this variable? R does not have a standard in-built function to calculate the mode. As we still want to show the mode, we create a user function to calculate the mode of our data set. This function takes a numeric vector as input and gives the mode value as output. Note You do not have to worry about creating your own functions, so just copy and paste the code below to create the get_mode() function. # create a function to calculate the mode get_mode &lt;- function(x) { # get unique values of the input vector uniqv &lt;- unique(x) # select the values with the highest number of occurrences uniqv[which.max(tabulate(match(x, uniqv)))] } # calculate the mode of the 2011 population variable get_mode(London.Pop2011$Persons.2011) ## [1] 7375 Questions What is the level of measurement of our Persons.2011 variable? Nominal, ordinal, or interval/ratio? Even though we went through all the trouble to create our own function to calculate the mode, do you think it is a good choice to calculate the mode for this variable? Why? Why not? Although R does most of the hard work for us, especially with the mean() and the median() function, it is a good idea to once go through the calculations of these two central tendency measures ourselves. Let’s cacluate the mean step-by-step and then verify our results with the results of R’s mean() function. # get the sum of all values Persons.2011.Sum &lt;- sum(London.Pop2011$Persons.2011) # inspect the result Persons.2011.Sum ## [1] 8173941 # get the total number of observations Persons.2011.Obs &lt;- length(London.Pop2011$Persons.2011) # inspect the result Persons.2011.Obs ## [1] 33 # calculate the mean Persons.2011.Mean &lt;- Persons.2011.Sum / Persons.2011.Obs # inspect the result Persons.2011.Mean ## [1] 247695.2 # compare our result with R&#39;s built-in function mean(London.Pop2011$Persons.2011) == Persons.2011.Mean ## [1] TRUE Great. Our own calculation of the mean is identical to R’s built-in function. Now let’s do the same for the median. # get the total number of observations Persons.2011.Obs &lt;- length(London.Pop2011$Persons.2011) # inspect the result Persons.2011.Obs ## [1] 33 # order our data from lowest to highest Persons.2011.Ordered &lt;- sort(London.Pop2011$Persons.2011, decreasing=FALSE) # inspect the result Persons.2011.Ordered ## [1] 7375 158649 160060 182493 185911 186990 190146 199693 206125 219396 ## [11] 220338 231997 237232 239056 246270 253957 254096 254557 254926 258249 ## [21] 273936 275885 278970 288283 303086 306995 307984 309392 311215 312466 ## [ reached getOption(&quot;max.print&quot;) -- omitted 3 entries ] # get the number of the observation that contains the median value Persons.Median.Obs &lt;- (Persons.2011.Obs + 1)/2 # inspect the result Persons.Median.Obs ## [1] 17 # get the median Persons.2011.Median &lt;- Persons.2011.Ordered[Persons.Median.Obs] # inspect the result Persons.2011.Median ## [1] 254096 # compare our result with R&#39;s built-in function median(London.Pop2011$Persons.2011) == Persons.2011.Median ## [1] TRUE Questions For the calculation of the median: what does the decreasing=FALSE parameter in the sort() function do? What happens if we change this to decreasing=TRUE? Does this affect the results for the calculation of the median? Why? Why not? When extracting the median we using [Persons.Median.Obs] and not [17] to select our value. Although the results are identical, what would be a good reason to select the first option over the second option? When comparing our own calculation to R’s built-in function we are using two ‘equal to’ signs ==, what happens if we only use one ‘equal to’ = sign? Why? 2.3 Simple plots Before moving on to the second set of descriptive statistics, the measures of dispersion, this is a good moment to note that simple data visualisations are also an extremely powerful tool to explore your data. In fact, tools to create high quality plots have become one of R’s greatest assets. This is a relatively recent development since the software has traditionally been focused on the statistics rather than visualisation. The standard installation of R has base graphic functionality built in to produce very simple plots. For example we can plot the relationship between the London population in 1811 and 1911. Note Next week we will be diving deeper into data visualisation and making plots and graphs in R, but for now it is a good idea to already take a sneak peek at how to create some basic plots. # make a quick plot of two variables of the London population data set plot(London.Pop$Persons.1811,London.Pop$Persons.1911) Questions What happens if you change the order of the variables you put in the plot() function? Why? Instead of using the $ to select the columns of our data set, how else can we get the same results? The result of calling the plot() function, is a very simple scatter graph. The plot() function offers a huge number of options for customisation. You can see them using the ?plot help pages and also the ?par help pages (par in this case is short for parameters). There are some examples below (note how the parameters come after specifying the x and y columns). # add a title, change point colour, change point size plot(London.Pop$Persons.1811, London.Pop$Persons.1911, main=&#39;Quick Plot in R&#39;, col=&#39;blue&#39;, cex=2) # add a title, change point colour, change point symbol plot(London.Pop$Persons.1811, London.Pop$Persons.1911, main=&quot;Another Quick Plot in R&quot;, col=&#39;magenta&#39;, pch=22) Note For more information on the plot parameters (some have obscure names) have a look here: http://www.statmethods.net/advgraphs/parameters.html Recap In this section you have learnt how to: Calculate the mode, median, and mean of a variable in R. Make some simple scatter plots (in preparation for next week) to visualise your data. 2.4 Measures of dispersion When exploring your data, measures of central tendency alone are not enough as they only tell you what a ‘typical’ value looks like but they do not tell you anything about all other values. Therefore we also need to look at some measures of dispersion. Measures of dispersion describe the spread of data around a central value (e.g. the mean, the median, or the mode). The most commonly used measure of dispersion is the standard deviation. The standard deviation is a measure to summarise the spread of your data around the mean. The short video below will introduce you to the standard deviation as well as to three other measures of dispersion: the range, the interquartile range, and the variance. Video: Measures of dispersion [Lecture slides] [Watch on MS stream] For the rest of this tutorial we will change our data set to one containing the number of assault incidents that ambulances have been called to in London between 2009 and 2011. You will need to download a prepared version of this file called: ambulance-assault.csv and upload it to your working directory. It is in the same data format (csv) as our London population file so we use the read.csv() command again. File download File Type Link Assault Incidents London csv Download # load csv file from working directory London.Ambulance &lt;- read.csv(&#39;ambulance-assault.csv&#39;) # inspect the results head(London.Ambulance) ## BorCode WardName WardCode WardType Assault_09_11 ## 1 00AA Aldersgate 00AAFA Prospering Metropolitan 10 ## 2 00AA Aldgate 00AAFB Prospering Metropolitan 0 ## 3 00AA Bassishaw 00AAFC Prospering Metropolitan 0 ## 4 00AA Billingsgate 00AAFD Prospering Metropolitan 0 ## 5 00AA Bishopsgate 00AAFE Prospering Metropolitan 188 ## 6 00AA Bread Street 00AAFF Prospering Metropolitan 0 # inspect the size of the data set nrow(London.Ambulance) ## [1] 649 You will notice that the data table has 5 columns and 649 rows. The column headings are abbreviations of the following: Column heading Full name Description BorCode Borough Code London has 32 Boroughs (such as Camden, Islington, Westminster, etc.) plus the City of London at the centre. These codes are used as a quick way of referring to them from official data sources. WardName Ward Name Boroughs can be broken into much smaller areas known as Wards. These are electoral districts and have existed in London for centuries. WardCode Ward Code A statistical code for the wards above. WardType Ward Type A classification that groups wards based on similar characteristics. Assault_09_11 Assault Incidents The number of assault incidents requiring an ambulance between 2009 and 2011 for each ward in London. Let’s start by calculating two measures of central tendency by using the median() and mean() functions. # calculate the median of the assault incident variable median(London.Ambulance$Assault_09_11) ## [1] 146 # calculate the mean of the assault incident variable mean(London.Ambulance$Assault_09_11) ## [1] 173.4669 Questions How do you explain that the mean is larger than the median for this variable? Great. Let’s now calculate some measures of dispersion for our data: the range, the interquartile range, and the standard deviation. The calculation of the range is very straightforward as we only need to subtract the the minimum value from the the maximum value. We can find these values by using the built-in min() and max() functions. # get the minimum value of the assault incident variable min(London.Ambulance$Assault_09_11) ## [1] 0 # get the maximum value of the assault incident variable max(London.Ambulance$Assault_09_11) ## [1] 1582 # calculate the range 1582 - 0 ## [1] 1582 # or in one go max(London.Ambulance$Assault_09_11) - min(London.Ambulance$Assault_09_11) ## [1] 1582 Questions Why do we get a value of 0 when executing our min() function? What does this range mean? The interquartile range requires a little bit more work to be done as we now need to work out the values of the 25th and 75th percentile. Note A percentile is a score at or below which a given percentage of your data points fall. For example, the 50th percentile (also known as the median!) is the score at or below which 50% of the scores in the distribution may be found. # get the total number of observations London.Ambulance.Obs &lt;- length(London.Ambulance$Assault_09_11) # inspect the result London.Ambulance.Obs ## [1] 649 # order our data from lowest to highest London.Ambulance.Ordered &lt;- sort(London.Ambulance$Assault_09_11, decreasing=FALSE) # inspect the result London.Ambulance.Ordered ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 18 19 21 22 25 28 ## [24] 28 28 29 30 34 36 36 ## [ reached getOption(&quot;max.print&quot;) -- omitted 619 entries ] # get the number (&#39;index value&#39;) of the observation that contains the 25th percentile London.Ambulance.Q1 &lt;- (London.Ambulance.Obs + 1)/4 # inspect the result London.Ambulance.Q1 ## [1] 162.5 # get the number (&#39;index value&#39;) of the observation that contains the 75th percentile London.Ambulance.Q3 &lt;- 3*(London.Ambulance.Obs + 1)/4 # inspect the result London.Ambulance.Q3 ## [1] 487.5 # get the 25th percentile London.Ambulance.Ordered[163] ## [1] 86 # get the 75the percentile London.Ambulance.Ordered[488] ## [1] 233 # get the interquartile range 233 - 86 ## [1] 147 As explained in the short lecture video, we can also visually represent our range, median, and interquartile range using a box and whisker plot: # make a quick boxplot of our assault incident variable boxplot(London.Ambulance$Assault_09_11, horizontal=TRUE) Questions There is a large difference between the range that we calculated and the interquartile range that we calculated. What does this mean? The 25th and 75th percentile in the example do not return integer but a fraction (i.e. 162.5 and 487.5). Why do we use 163 and 488 to extract our percentile values and not 162 and 487? Now, let’s move to the standard deviation. Remember: this is one of the most important measures of dispersion and is widely used in all kinds of statistics. The calculation involves the following steps: Calculate the mean. Subtract the mean from each observation to get a residual. Square each residual. Sum all residuals. Divide by \\(n-1\\). Take the square root of the final number. # calculate the mean London.Ambulance.Mean &lt;- mean(London.Ambulance$Assault_09_11) # subtract the mean from each observation London.Ambulance.Res &lt;- London.Ambulance$Assault_09_11 - London.Ambulance.Mean # square each residual London.Ambulance.Res.Sq &lt;- London.Ambulance.Res**2 # sum all squared residuals London.Ambulance.Res.Sum &lt;- sum(London.Ambulance.Res.Sq) # divide the sum of all sqaured residuals by n - 1 London.Ambulance.Variance &lt;- London.Ambulance.Res.Sum / (length(London.Ambulance$Assault_09_11) - 1) # take the square root of the final number London.Ambulance.Sd &lt;- sqrt(London.Ambulance.Variance) # standard deviation London.Ambulance.Sd ## [1] 130.3482 There we go. We got our standard deviation! You probably already saw this coming, but R does have some built-in functions to actually calculate these descriptive statistics for us: range(), IQR(), and sd() will do all the hard work for us! # range range(London.Ambulance$Assault_09_11) ## [1] 0 1582 # interquartile range IQR(London.Ambulance$Assault_09_11) ## [1] 147 # standard deviation sd(London.Ambulance$Assault_09_11) ## [1] 130.3482 Note Please be aware that the IQR() function may give slighlty different results in some cases when compared to a manual calculation. This is because the forumula that the IQR() function uses is slightly different than the formula that we have used in our manual calculation. It is noted in the documentation of the IQR() function that: “Note that this function computes the quartiles using the quantile function rather than following Tukey’s recommendations, i.e., IQR(x) = quantile(x, 3/4) - quantile(x, 1/4).” Questions What does it mean that we have a standard deviation of 130.3482? Given the context of the data, do you think this is a low or a high standard deviation? To make things even easier, R also has a summary() function that calculates a number of these routine statistics simultaneously. After running the summary() function on our assault incident variable, you should see you get the minimum (Min.) and maximum (Max.) values of the assault_09_11 column; its first (1st Qu.) and third (3rd Qu.) quartiles that comprise the interquartile range; its the mean and the median. The built-in R summary() function does not calculate the standard deviation. There are functions in other libraries that calculate more detailed descriptive statistics, # calculate the most common descriptive statistics for the assault incident variable summary(London.Ambulance$Assault_09_11) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 86.0 146.0 173.5 233.0 1582.0 Recap In this section you have learnt how to: Calculate the range, interquartile range, and standard deviation in R. Create a simple boxplot using the boxplot() function. Quickly get common descriptive statistics using the summary() function. 2.5 Seminar Please find the seminar task and seminar questions for this week’s seminar below. Note Please make sure that you have executed the seminar task and have answered the seminar questions before the seminar! Seminar task Using the London.Ambulance object: Create a new object / data set that only contains data for ward type Multicultural Metropolitan. Create a new object / data set that only contains data for ward type Prospering Metropolitan. Note Creating a new object from an existing object is called creating a subset of your data. There are many ways of creating a subset, but one way of doing it is by using the following syntax: London.Assault[London.Assault$WardType == 'Multicultural Metropolitan',]. For both new objects: Calculate the median, mean, range, interquartile range, and standard deviation for the Assault_09_11 variable. Create a boxplot of the Assault_09_11 variable. Seminar questions Explain why each of these statistics are useful and what type of data are required to calculate them: Mode Median Mean Range Interquartile Range Standard Deviation Compare the results of the descriptive statistics you have calculated for your Multicultural Metropolitan object / data set with the results of the descriptive statistics you have calculated for you Prospering Metropolitan object / data set. What do these differences tell us? In which of these two ward types are the data more clustered? In which of these two ward types are the data more dispersed? Seminar link Seminars for all groups take place on Thursday morning. You can find the Zoom link to your seminar group on Moodle. 2.6 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "],
["examining-data-ii.html", "3 Examining data II 3.1 Introduction 3.2 Data visualisation 3.3 ggplot2 3.4 Seminar 3.5 Before you leave", " 3 Examining data II 3.1 Introduction Welcome to your third week of Introduction to Quantitative Research Methods. This week we will focus again on examining data, however, this time we will focus on data visualisation. For the tutorial we will use both data sets that we used over the last two weeks. A picture good data visualisation is worth a thousand words. This week is structured by 5 short videos, practical material that you need to work through in preparation for Thursday’s seminar, and a seminar task that you need to do in preparation for Thursday’s seminar. Let’s go. Video: Introduction W03 [Lecture slides] [Watch on MS stream] 3.1.1 Reading list Please find the reading list for this week below. We strongly recommend that you read the core reading material before you continue with the rest of this week’s material. Core reading Lane et al., 2003, Chapter 3: Graphing Distributions. In: Lane et al., 2003, Introduction to Statistics. Houston, Texas: Rice University. [Link] Supplementary reading Langton and Solymosi, 2019, Cartograms, hexograms and regular grids: Minimising misrepresentation in spatial data visualisations. Environment and Planning B: Urban Analytics and City Science. Advance Online Publication. [Link] 3.1.2 Q&amp;A session This week there will be a live Q&amp;A session on Tuesday, January 26, 2020 @ 11h00 (GMT). The session will be hosted on Zoom [Link]. For security reasons, the meeting password for this Q&amp;A session can be found on Moodle on the main page (POLS0008 - Q&amp;A - Tuesday 11:00). 3.2 Data visualisation Data visualisation is the representation of data in a visual format. This could be a graph, chart, map, or other visual format. Sometimes the visualisation includes every data point, for instance in case of a scatter graph, or sometimes it shows some type of statistical summary, for instance in case of a boxplot. Sometimes visualisations are very descriptive and only include the raw data, whilst other times they are the product of a sequence of transformations and analyses. No matter what, the main goal of data visualisation is to help you interpret the underlying data. Data visualisation is therefore used when cleaning your data, exploring your data, looking for outliers and unusual values, identifying trends, identifying clusters, uncovering patterns, and presenting results. Video: Data visualisation I [Lecture slides] [Watch on MS stream] Before we move to R and start creating some data visualisations ourselves, a good example, albeit slightly dated, of why data visualisation is so important, is given by the late Hans Rosling. He was a Swedish physician and statistician who was very passionate about data visualisation. As he says in the video: “Having the data is not enough. I have to show it in ways people both enjoy and understand”. Video: Data visualisation II [Lecture slides] [Watch on YouTube] For this tutorial we start by using the London.Pop object again that we created during our tutorial in Week 01 and that we also briefly used during last week’s tutorial. You may still have it loaded into your R workspace if your RStudio Server session is still active. To check if you do, you can use the ls() command as usual to get a list of all objects that are available in your RStudio session. If not you can simply reload it: # set the working directory path to the folder you wish to use # this would be the folder that you created during last week&#39;s practical setwd(&#39;~/POLS0008&#39;) # note the single / (\\\\ will also work) If you struggle with setting up your working directory and you need a reminder, have a look at how we set this up in our first week! # load csv file from working directory London.Pop &lt;- read.csv(&#39;census-historic-population-borough.csv&#39;) Now are data are loaded again, we can start by recreating a simple scatter graph in a similar fashion as we did last week using the plot() function. # make a quick scatter plot of two variables of the London population data set plot(London.Pop$Persons.2001,London.Pop$Persons.2011) Questions What do the points in the graph represent? Do you think there is a relationship between the population in London’s boroughs in 2001 and the population in London’s boroughs in 2011? If so, what is this relationship? How can we add a title? How can we change the colour of the points? Another common method to visualise your data is by using a line chart. Line charts are particularly useful when you want to compare change over time, for example. A line chart can also be relatively easily created in R. Let’s try it by charting the population size over time for one of London’s boroughs: Hackney. # select the data for the borough of Hackney London.Hackney &lt;- London.Pop[London.Pop$Area.Name==&#39;Hackney&#39;,3:24] # inspect the result London.Hackney ## Persons.1801 Persons.1811 Persons.1821 Persons.1831 Persons.1841 ## 12 50000 64000 80000 105000 128000 ## Persons.1851 Persons.1861 Persons.1871 Persons.1881 Persons.1891 ## 12 170000 218000 261000 329000 372000 ## Persons.1901 Persons.1911 Persons.1921 Persons.1931 Persons.1939 ## 12 389000 385000 379000 364000 332000 ## Persons.1951 Persons.1961 Persons.1971 Persons.1981 Persons.1991 ## 12 265000 257522 220000 180434 162772 ## Persons.2001 Persons.2011 ## 12 202825 246270 The crucial part of the code snippet above is what’s included in the square brackets [ ]. We are subsetting the London.Pop object, but instead of telling R what column names or numbers we require, we are requesting all rows in the Area.Name column that contain Hackney. Hackney is a text string so it needs to go in speech marks '' (or \"\") and we need to use two equals signs == in R to mean “equal to”. A single equals sign = is another way of assigning objects. Although = works the same way as &lt;-, it is much less widely used for this purpose because it is also used when parameterising functions. We should now be left with a dataframe that only contains one row of data: the data for the borough of Hackney. This does raise a question: how do we include all the variables into our plot as all our data are spread out over different columns (i.e. Persons1801, Persons1811, etc.)? Ideally we would flip the data set around so that all the data (i.e. Persons1801, Persons1811, etc.) would be in one column. Well, luckily we can actually do that by transposing our data set. Transposing is a mathematical operation to flip a matrix over its diagonal. Effectively, it turns rows into columns and columns into rows. In R we can do this using the t() function. # flip the rows and columns of our data set London.Hackney.t &lt;- t(London.Hackney) # inspect the result London.Hackney.t ## 12 ## Persons.1801 50000 ## Persons.1811 64000 ## Persons.1821 80000 ## Persons.1831 105000 ## Persons.1841 128000 ## Persons.1851 170000 ## Persons.1861 218000 ## Persons.1871 261000 ## Persons.1881 329000 ## Persons.1891 372000 ## Persons.1901 389000 ## Persons.1911 385000 ## Persons.1921 379000 ## Persons.1931 364000 ## Persons.1939 332000 ## Persons.1951 265000 ## Persons.1961 257522 ## Persons.1971 220000 ## Persons.1981 180434 ## Persons.1991 162772 ## Persons.2001 202825 ## Persons.2011 246270 # plot the size of the population in the London borough of Hackney over time plot(London.Hackney.t, type=&#39;b&#39;) Questions Why did we slice our data frame when we selected the data for Hackney (i.e. London.Pop[London.Pop$Area.Name=='Hackney',3:24]) and did we not simply keep all columns? How can we change the colour of the line and points in our graph? Note You may be wondering why the first column of the transposed dataframe does not have a column name and why the column with the data of the transposed dataframe is called 12. The reason for this is that the t() function flips the row and column indices around. The column indices (i.e. in this case the column names) now become row names and the row indices (i.e. in this case row numbers) now become column names (the data for Hackney can be found on row number 12 in the original data set). However, do not worry about this too much for now. Last week you also got introduced to the box and whisker plot. A box and whisker plot is a method for visualising your data by their quartiles with the whiskers (the lines extending from the box) incidating the variability of the values outside the lower and upper quartile. Typically outliers are plotted as individual points. Let’s go back to our full data set and make a boxplot for one of the population variables in the London population data set. # make a boxplot of one of the variables in the London population data set boxplot(London.Pop$Persons.2001,horizontal=TRUE) The standard plot() and boxplot functions offer a huge number of options for customisation. A useful option is to combine multiple graphs into one figure to allow for easy comparison. We can do this by setting some of the graphical parameters and requesting that our graphs are plotted together. # specify that we want an output consisting of two rows par(mfrow=c(2,1)) # make a boxpot of one of the variables in the London population data set boxplot(London.Pop$Persons.2001,horizontal=TRUE) # make a boxplot of another variable in the London population data set boxplot(London.Pop$Persons.2011,horizontal=TRUE) Note The specification given to the par() function only works once: it is not an option that you switch on and once the option is switched on all plots will be plotted together. This also means that if you run this code line by line, you will not get the result you want. In order to get both boxplots to show in one figure, you need to highlight all three lines and then run the code. Questions The boxplots of the population in London’s boroughs in 2001 and the population in London’s boroughs in 2011 are clearly different. What differences are there and what does this mean? Why is it currently difficult to compare these two boxplots? What happens if we update our parameters to par(mfrow=c(1,2))? The last type of plot we will introduce to you today is called a histogram. As explained in the lecture video, a histogram is a graphical display of data using bars of different heights. It is therefore quite similar to a bar chart, however, with a histogram we group our values into bins. We can create in histogram in R using the hist() function. # make a histogram of one of the variables in the London population data set hist(London.Pop$Persons.2001) Currently R automatically picks the width of the bins in which the data are grouped. To change the width of these bins, we can specify the breaks parameter: # create a vector with break values bindwidth &lt;- c(0,100000,200000,300000,400000) # make a histogram of one of the variables in the London population data set hist(London.Pop$Persons.2001,breaks=bindwidth) Recap In this section you have learnt how to: Create a simple line chart in R. Combine multiple graphs into one figure. Create a histogram in R. 3.3 ggplot2 The graphs and figures we have made so far are not really pretty. Although possible with the basic R installation, there are easier and better ways to make nice visualisations. For this we can turn to other R packages that have been developed. In fact, there are many hundreds of packages in R each designed for a specific purpose, some of which you can use to create plots in R. One of those packages is called ggplot2. The ggplot2 package is an implementation of the Grammar of Graphics (Wilkinson 2005) - a general scheme for data visualisation that breaks up graphs into semantic components such as scales and layers. ggplot2 can serve as a replacement for the base graphics in R and contains a number of default options that match good visualisation practice. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. Video: ggplot2 [Lecture slides] [Watch on MS stream] As there are many hundreds of R packages, these hese are not installed automatically. This means that every additional package we want to use needs to be downloaded and then we need to load it into R in order to use it. To download and install the ggplot2 package type the following: # install package install.packages(&#39;ggplot2&#39;) Figure 3.1: Installing the ggplot2 package. Note If you are running RStudio on your own computer: when you hit ‘enter’ you could be asked to select a mirror to download the package contents from. It does not really matter which one you choose, but we would suggest you pick the mirror that is geographically closest to you. The install.packages() step only needs to be performed once. You do not need to install a the package every time you want to use it. However, each time you open R, or start a new R session in RStudio Server, and wish to use a package you need to use the library() command to tell R that it will be required. # load ggplot2 package library(ggplot2) Video: Installing packages in R [Lecture slides] [Watch on MS stream] Now we installed ggplot2 and loaded it into our R session, we can start by trying to make a basic plot using the ggplot2 package ourselves. Let’s continue for a little while longer with our London.Pop object. # create a ggplot2 object named &#39;p&#39; p &lt;- ggplot(data=London.Pop, aes(Persons.1811, Persons.1911)) What you have just done is set up a ggplot object where you tell where you want the input data to come from – in this case it is our London.Pop object. The column headings within the aes() brackets refer to the parts of that data frame you wish to use (the variables Persons.1811 and Persons.1911). aes is short for aesthetics that vary – this is a complicated way of saying the data variables used in the plot. Let’s have a look at this object. # plot p As you can see, if you inspect the object p that we just created you will get an empty canvas. The reason for this is that you have not told ggplot what you want to do with the data. We do this by adding so-called geoms, geometries. Let’s try to create a scatter plot. We can do this by using the geom geom_point(): # add our geom to our &#39;p&#39; object p &lt;- p + geom_point() # plot p You can already see that this plot is looking a bit nicer than the scatterplot we created with the base plot() function used above. Within the geom_point() brackets you can alter the appearance of the points in the plot. Questions Try to change the colour and size of the points in your scatterplot by specifying the colour and size parameter, for instance, p + geom_point(colour='red', size=2). What other parameters can you pass to the geom_point() function? Note Whilst these instructions are step by step, you are strongly encouraged to deviate from them, for instance, by trying different colours, to get a better understanding of what we are doing. For further help, ggplot2 is one of the best documented packages in R and large volumes of documentation are available. If you want to explore ggplot2 further, we would also recommend taking a look at the ggplot2 tutorial for beautiful plotting in R by by Cédric Scherer. Rather than colouring your points by one colour, you can also colour the points according to another variable. You can do this by adding the desired variable into the aes() section after geom_point(). Here we will do this to indicate the size of the population in 2011 as well as the relationship between the size of the population in 1811 and 1911. # add some more aesthetics that vary p + geom_point(aes(colour = Persons.2011), size = 2) You will notice that ggplot has also created a key that shows the values associated with each colour. In this slightly contrived example it is also possible to resize each of the points according to the Persons.2011 variable. # add some more aesthetics that vary p + geom_point(aes(size = Persons.2011)) The real power of ggplot2 lies in its ability to build a plot up as a series of layers. This is done by stringing plot functions (geoms) together with the + sign. For instance, we can add a text layer to the plot using geom_text(). Note This idea of layers (or geoms) is quite different from the standard plot functions in R, but you will find that each of the functions does a lot of clever stuff to make plotting much easier (see the ggplot2 documentation for a full list). # add a geom_text to the plot p + geom_point(aes(size = Persons.2011)) + geom_text(size = 2, colour=&#39;red&#39;, aes(label = Area.Name)) The above code adds London Borough labels to the plot over the points they correspond to. This is not perfect since many of the labels overlap but they serve as a useful illustration of the layers. To make things a little easier the plot can be saved as a pdf using the ggsave() command. When saving the plot can be enlarged using the scale parameter to help make the labels more legible. # save the plot ggsave(&#39;first_ggplot.pdf&#39;, scale=2) Questions Where does your plot get saved? Why? Please note that ggsave() only works with plots that were created with ggplot. Within the brackets you specify the file name for the plot, but as you can see in the example you also include the file format: in this case .pdf, but you could also save the plot as a .jpg file. The scale controls how many times bigger you want the exported plot to be than it currently is in the plot window. ggplot2 is not limited to scatterplots and we can also create more advanced plots such as histograms and box and whisker plots. Let’s first switch our data set to the one containing the number of assault incidents that ambulances have been called to in London between 2009 and 2011. As you will already have uploaded this ambulance-assault.csv file to your working directory last week, we can simply reload the file if it is not still loaded into your R workspace. # load csv file from working directory London.Ambulance &lt;- read.csv(&#39;ambulance-assault.csv&#39;) Histograms provide a nice way of graphically summarising a dataset, so let’s start by making a histogram for our assault incident variable. # create a ggplot2 object named &#39;p&#39; p &lt;- ggplot(London.Ambulance, aes(x=Assault_09_11)) # inspect p Questions Remember why printing/plotting the p object currently results in an empty canvas? The ggplot(London.Ambulance, aes(x=Assault_09_11)) section means “create a generic plot object (called p) from the input object using the Assault_09_11 column as the data for the x axis”. Remember the data variables are required as aesthetics parameters so the Assault_09_11 appears in the aes() brackets. To create the histogram you need to add the relevant ggplot2 command (geom). # add geom to our &#39;p&#39; object p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The height of each bar (the x-axis) shows the count of the datapoints and the width of each bar is the value range of datapoints included. If you want the bars to be thinner (to represent a narrower range of values and capture some more of the variation in the distribution) you can adjust the bin width. Bin width controls the size of ‘bins’ that the data are split up into. Try: # add geom to our &#39;p&#39; object, adjust the bin width settings p + geom_histogram(, binwidth=10) This plot has provided a good impression of the overall distribution, but it would be interesting to see characteristics of the data within each of the Boroughs. We can do this since each Borough in the London.Ambulance object is made up of multiple wards. To see what we mean, we can select all the wards that fall within the Borough of Camden, which has the code 00AG (if you want to see what each Borough the code corresponds to, and learn a little more about the statistical geography of England and Wales, then do have a look here. # filter the data set camden &lt;- London.Ambulance[London.Ambulance$BorCode==&#39;00AG&#39;,] Just like before, the crucial part of the code snippet above is what’s included in the square brackets. Again we are subsetting the London.Ambulance object, but instead of telling R what column names or numbers we require, we are requesting all rows in the BorCode column that contain 00AG. Let’s quickly compare our original London.Pop object with our newly created camden object: # inspect the ambulance assault incident data set nrow(London.Pop) ## [1] 33 # inspect the ambulance assault incident data set for Camden nrow(camden) ## [1] 18 # inspect the ambulance assault incident data set for Camden head(camden) ## BorCode WardName WardCode ## 128 00AG Belsize 00AGGD ## 129 00AG Bloomsbury 00AGGE ## 130 00AG Camden Town with Primrose Hill 00AGGF ## 131 00AG Cantelowes 00AGGG ## 132 00AG Fortune Green 00AGGH ## 133 00AG Frognal and Fitzjohns 00AGGJ ## WardType Assault_09_11 ## 128 Prospering Metropolitan 91 ## 129 Prospering Metropolitan 315 ## 130 Prospering Metropolitan 535 ## 131 Multicultural Metropolitan 238 ## 132 Prospering Metropolitan 106 ## 133 Prospering Metropolitan 77 Questions Why do we have to use double quotes ('') to subset out dataframe to get all rows that contain 00AG? So to produce a histogram for Camden, the code above needs to be replicated using the camden object in the place of London.Pop: # create a ggplot2 object named &#39;p.camden&#39; p.camden &lt;- ggplot(camden, aes(x=Assault_09_11)) # add geom to our &#39;p.camden&#39; object p.camden + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # plot pretty(ish) p.camden + geom_histogram() + ggtitle(&#39;Assault incidents in Camden&#39;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Questions What do the values on the x-axis of our histogram mean? What do the values on the y-axis of our histogram mean? As you can see this histogram looks a little different than the histogram for the entire data set did. This is largely because we have relatively few rows of data in the camden object (as we saw when using nrow(camden)). Nevertheless it would be interesting to see the data distributions for each of the London Boroughs. It is a chance to use the facet_wrap() function in R. This brilliant function lets you create a whole load of graphs at once! # note that we are back to using the `p` object since we need all our data for this # this code may generate a large number of warning messages relating to the plot bin width, don&#39;t worry about them p + geom_histogram() + facet_wrap(~BorCode) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Yes. It is that easy. Let’s try using facet_wrap() to plot according to Ward type: # note that we are back to using the `p` object since we need all our data for this # this code may generate a large number of warning messages relating to the plot bin width, don&#39;t worry about them p + geom_histogram() + facet_wrap(~WardType) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The facet_wrap() part of the code simply needs the name of the column you would like to use to subset the data into individual plots. Before the column name a tilde ~ is used as shorthand for “by” - so using the function we are asking R to facet the input object into lots of smaller plots based on the BorCode column in the first example and WardType in the second. Questions Use the facet_wrap() help file to learn how to create the same plot but with the graphs arranged into 4 columns. Which parameters need to be specified? In addition to histograms, another type of plot that, as we know, shows the core characteristics of the distribution of values within a data set is a box and whisker plot. These too can be easily produced using the ggplot2 package: # note that the `Assault_09_11` column is now y and not x # we specify x = &#39;London&#39; to add a meaningfull label to the x-axis p.boxplot &lt;- ggplot(London.Ambulance, aes(x=&#39;London&#39;, y=Assault_09_11)) # add the boxplot geom p.boxplot + geom_boxplot() If we are just interested in Camden then we can use the camden object created above in the code. # boxplot for camden only # we speficy x = &#39;Camden&#39; to add a meaningfull label to the x-axis p.boxplot.camden &lt;- ggplot(camden, aes(x=&#39;Camden&#39;, y=Assault_09_11)) # add the boxplot geom p.boxplot.camden + geom_boxplot() If you prefer you can flip the plot 90 degrees so that it reads from left to right: # add the boxplot geom and rotate p.boxplot.camden + geom_boxplot() + coord_flip() You can see that Camden looks a little different to the boxplot of the entire dataset. It would therefore be useful to compare the distributions of data within each of the Boroughs in a single plot as we did with the histograms above. ggplot2 makes this very easy (again!), we just need to change the x parameter to the Borough code column (BorCode). # boxplot for camden only p.boxplot.all &lt;- ggplot(London.Ambulance, aes(x=BorCode, y=Assault_09_11)) # add the boxplot geom and rotate p.boxplot.all + geom_boxplot() + coord_flip() Recap In this section you have learnt how to: Install and load additional packages in R. Learned the basics of the ggplot2 package for creating plots. Learned what geoms are in the context of ggplot2. Learned how to specify data variables with the aes() parameter. Utilised some of the advanced functionality as part of the ggplot2 package, not least through the creation of facetted histogram plots using geom_histogram() and facet_wrap() and also box and whisker plots with geom_boxplot(). 3.4 Seminar Please find the seminar task and seminar questions for this week’s seminar below. Note Please make sure that you have executed the seminar task and have answered the seminar questions before the seminar! Seminar task Create a histogram of the Assault_09_11 variable for the London borough of Ealing (Borough code 00AJ), you need to: Use the ggplot2 library. Add a title using ggtitle(). Change the colour of the visualisation. Use a bin width of 75. Save your histogram as a pdf. Create a histogram of the Assault_09_11 variable for the London borough of Ealing (Borough code 00AJ), you need to: Use the ggplot2 library. Add a title using ggtitle(). Change the colour of the visualisation. Use a bin width of 100. Save your histogram as a pdf. Create a boxplot of the Assault_09_11 variable for the London borough of Croydon (Borough code 00AH), you need to: Use the ggplot2 library. Add a title using ggtitle(). Change the colour of the visualisation. Save your boxplot as a jpg. For all three visualisations, try to figure out how to: Change the name of the x-axis using xlab(). Change the name of the y-axis using ylab(). Seminar questions Explain why each of these visualisations are useful and what type of data are required to calculate them: Scatter plot Histogram Box and whisk plot Line chart Compare the results of the histograms you created of the Assault_09_11 variable for the borough of Ealing using a bin width of 75 with the histogram you created for the borough of Ealing using a bin width of 100. Why do they look so different? What does this tell you about the selection of bin widths? Seminar link Seminars for all groups take place on Thursday morning. You can find the Zoom link to your seminar group on Moodle. 3.5 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "],
["sourcing-data.html", "4 Sourcing data 4.1 Introduction 4.2 Sourcing data 4.3 Preparing data 4.4 Seminar 4.5 Before you leave", " 4 Sourcing data 4.1 Introduction Welcome to your fourth week of Introduction to Quantitative Research Methods. This week we will introduce you to sourcing and preparing data from official sources. For the tutorial we will apply what we have learnt over the past weeks onto a new data set. This week is structured by 4 short videos, practical material that you need to work through in preparation for Thursday’s seminar, and a seminar task that you need to do in preparation for Thursday’s seminar. Let’s do it. Video: Introduction W4 [Lecture slides] [Watch on MS stream] 4.1.1 Reading list Please find the reading list for this week below. We strongly recommend that you read the core reading material before you continue with the rest of this week’s material. Core reading Wickham, 2014, Tidy data, Journal of Statistical Software 59(10). [Link] Supplementary reading Zhang et al., 2010, Data preparation for data mining. Applied Artificial Intelligence 17(5-6): 375-381. [Link] 4.1.2 Q&amp;A session This week there is NO live Q&amp;A session scheduled. Please post any questions you have on the POLS0008 Forum or ask them to your seminar leader during your live seminar on Thursday. 4.2 Sourcing data Over the past weeks we have predominantly worked with two data sets that we provided for you: ambulance-assault.csv and census-historic-population-borough.csv. Although these data sets are very useful to give you an introduction to Quantitative Research methods, in real life data you will have to source your own data. In the case of the social sciences, you often can find socio-economic data on the websites of national statistical authorities such as the Office for National Statistics, United States Census Bureau, Statistics South Africa, or the National Bureau of Statistics of China. Also large international institutions like World Bank and Unicef compile socio-economic data sets and make these available for research purposes. No matter where you will be getting your data from, however, you will have to know how to download and prepare these data sets in such a way that you can work with them in R to conduct your analysis. Video: Sourcing data I [Lecture slides] [Watch on MS stream] Within the United Kingdom, the Office for National Statistics (ONS) is the largest producer of official statistics. ONS is responsible for collecting and publishing statistics related to the economy, population and society at national, regional and local levels. They are also responsible for conducting the census in England and Wales every 10 years (the census for Scotland and Northern Ireland are conducted by the National Records of Scotland and the Northern Ireland Statistics and Research Agency, respectively). Today we will be downloading a data set from ONS, prepare the data set as a csv file, and read our freshly created csv file into R. Figure 4.1: The website of the Office for National Statistics. Because the population data in the census-historic-population-borough.csv we have been working with so far only goes as far as 2011, we will try to get some more recent population estimates on the ‘usual resident population’. Every year, ONS releases a new set of Middle Super Output Area mid-year population estimates. Currently, the latest available data set is that of mid-2019 and this is the data set that we are now going to download and prepare. Note The mid-year population estimates that we will be downloading are provided by ONS at the Middle Super Output Area (MSOA) level. MSOAs are one of the many administrative geographies that the ONS uses for reporting their small area statistics. An administrative geography is a way of dividing the country into smaller sub-divisions or areas that correspond with the area of responsibility of local authorities and government bodies. These geographies are updated as populations evolve and as a result, the boundaries of the administrative geographies are subject to either periodic or occasional change. The UK has quite a complex administrative geography, particularly due to having several countries within one overriding administration and then multiple ways of dividing the countries according to specific applications. To download the data set, you need to take the following steps: Step Action 1 Navigate to the download page of the Middle Super Output Area population estimates: [Link] 2 Download the file Mid-2019: SAPE22DT14 to your computer. 3 Because the file that you have now downloaded is a zip file, we first need to extract the file before we can use it. To unzip the file you can use the built-in functionality of your computer’s operating system. For Windows: right click on the zip file, select Extract All, and then follow the instructions. For Mac OS: double-click the zip file. 4 Open the file in Microsoft Excel or any other spreadsheet software. Please note that the instructions provided below use only cover Microsoft Excel. 5 Once opened your file should look similar as the screenshot in Figure 4.2. Figure 4.2: The Mid-2019: SAPE22DT15 file that we downloaded. The file probably does not look exactly like you thought it would because we do not directly see any data! In fact, ONS has put the data on different tabs. Some of these tabs contain the actual data, whilst others contain some meta-data and notes and definitions. The data that we want to use is found on the Mid-2019 Persons tab: the total number of people living in each MSOA. The problem we have now, however, is that the data as it is right now cannot be read into R without causing us lots of problems down the road. So even though we have the data we want to work with at our finger tips, we are not yet ready to read our data set into R! So, in video below, we will show you how to create a csv from the data that we want to use. Video: Sourcing data II [Lecture slides] [Watch on MS stream] Now you have seen how to prepare your csv, it is time to do it yourselves. Just as a small recap, these are the steps that you need to take to turn the downloaded data into a csv: Step Action 1 Open the downloaded file in Microsoft Excel and activate the Mid-2019 Persons tab. 2 Highlight the columns: MSOA Code, MSOA Name, LA Code (2019 boundaries), LA name (2019 boundaries), LA Code (2020 boundaries), LA name (2020 boundaries), and All Ages. Do make sure that you do not include any of the whitespace or empty rows. 3 Scroll down all the way to the bottom of the file. Now hold down the shift button and click on the last value in the All Ages column. This value should be 9,711. All data should now be selected. 4 Now all the data that we need are selected we can copy them by right clicking and in the context menu opting for the copy option. Of course, you can also simply use control + c (Windows) or command + c (Mac OS). 5 Open a new, empty spreadsheet and paste the copied data into this new, empty spreadsheet. You can paste your copied data by right clicking on the first cell (A1) and in the context menu opting for the paste option. Of course, you can also simply use control + v (Windows) or command + v (Mac OS). 6 Conduct a visual check to make sure that you copied all the data. 7 Conduct a visual check to make sure that you did not copy any additional data. 8 Remove all formatting and make sure that empty columns are indeed empty. 9 Save this file as a midyear2019.csv. Make sure that you select csv as your file format (e.g. CSV UTF8 (Comma-delimited) (.csv)). 10 Inspect your data in a text editor such as Wordpad or Textedit to make sure the file you created is indeed a comma-separated file. Now, for the moment of truth: let’s try and see if we can load our data into R! Of course, you will first need to upload your csv file to RStudio Server and set your working directory so that R can find the file - but you should be able to do that without any problems by now. # load csv file from working directory midyear &lt;- read.csv(&#39;midyear2019.csv&#39;) ## MSOA.Code MSOA.Name LA.Code..2019.boundaries. ## 1 E02002483 Hartlepool 001 E06000001 ## 2 E02002484 Hartlepool 002 E06000001 ## 3 E02002485 Hartlepool 003 E06000001 ## 4 E02002487 Hartlepool 005 E06000001 ## LA.name..2019.boundaries. LA.Code..2020.boundaries. ## 1 Hartlepool E06000001 ## 2 Hartlepool E06000001 ## 3 Hartlepool E06000001 ## 4 Hartlepool E06000001 ## LA.name..2020.boundaries. All.Ages ## 1 Hartlepool 10 261 ## 2 Hartlepool 10 449 ## 3 Hartlepool 8 185 ## 4 Hartlepool 5 277 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 7197 rows ] Questions Inspect the column names. Why do you think that they slightly differ from the ones that we saw in Microsoft Excel? How many rows does the midyear dataframe have? How many columns does the midyear dataframe have? The column names may seem a little complicated but in fact simply refer to some of the administrative geographies that the ONS uses for their statistics. Don’t worry if you do not fully understand these as they are notoriously complicated and confusing! Column heading Full name Description MSOA.Code MSOA Code Middle Super Output Areas are one of the many administrative geographies that the ONS uses for reporting their small area statistics. These codes are used as a quick way of referring to them from official data sources. MSOA.Name MSOA Name Name of the MSOA. LA.Code..2019.boundaries Local Authority District codes 2019 Local Authority Districts are a subnational division used for the purposes of local government. Each MSOA belongs to one Local Authority District, however, between years the boundaries of these Local Authority Districts sometimes change. These are the codes of the Local Authority District to which the MSOA belonged to in 2019. LA.name..2019.boundaries Local Authority District names 2019 Name of the Local Authority District to which the MSOA belonged to in 2019. LA.Code..2020.boundaries Local Authority District codes 2020 Code of the Local Authority District to which the MSOA belonged to in 2020 LA.name..2020.boundaries Local Authority District names 2020 Name of the Local Authority District to which the MSOA belonged to in 2019. All.Ages Total number of people The total number of people that is estimated to live in the MSOA mid-2019. Now we at least have an idea about what our column names mean, we can rename them so that they are a little more intelligible and easier to work with in a later stage. # rename columns names(midyear) &lt;- c(&#39;msoa_code&#39;,&#39;msoa_name&#39;,&#39;lad19_code&#39;,&#39;lad19_name&#39;,&#39;lad20_code&#39;,&#39;lad20_name&#39;,&#39;pop19&#39;) # inspect names(midyear) ## [1] &quot;msoa_code&quot; &quot;msoa_name&quot; &quot;lad19_code&quot; &quot;lad19_name&quot; &quot;lad20_code&quot; ## [6] &quot;lad20_name&quot; &quot;pop19&quot; # write to new csv write.csv(midyear, &#39;midyear2019_v2.csv&#39;, row.names=FALSE) Great. This is all looking very good but we are not completely there yet. Now we sourced our data and managed to successfully read the data set into R, we will need to do conduct some final preparations so that our data is analysis ready. Recap In this section you have learnt how to: Download data from the Office for National Statistics. Select the data that you need and save these into a csv file. Load the csv file that you created into R. 4.3 Preparing data Even though the data set that we downloaded came from an official national statistical authority, the data is not directly ready for analysis. In fact, the vast majority of the data you will find in the public domain (or private domain for that matter) will be dirty data. With dirty data we mean data that needs some level of pre-processing, cleaning, and linkage before you can use it for your analysis. In the following, you will learn a consistent way to structure your data in R: tidy data. Tidy data, as formalised by R expert Hadley Wickham in his contribution to the Journal of Statistical Software is not only very much at the core of the tidyverse R package that we will introduce you to, but also of general importance when organising your data. Video: Preparing data [Lecture slides] [Watch on MS stream] As you know by now, your basic R functionality (the base package) can be extended by installing additional packages. These packages are the fundamental units of reproducible R code and include functions, documentation, and sample data. Last week, we introduced you to the ggplot2 package: a general scheme for data visualisation that breaks up graphs into semantic components such as scales and layers. Today we will introduce you to the tidyverse package. This package is specifically created to make working with data, including data cleaning and data preparation, easier. Let’s start by installing the tidyverse package using the install_packages() function in the same way as we installed the ggplot2 package last week. # install the tidyverse install.packages(&#39;tidyverse&#39;) Note The tidyverse package is in fact a collection of packages that are specifically designed for data science tasks. Where in many cases different packages work all slightly differently, all packages of the tidyverse share the underlying design philosophy, grammar, and data structures. The ggplot2 package that you worked with last week is actually one of the core package of the tidyverse. This also means that if you load the tidyverse package through library(tidyverse) you directly have access to all the functions that are part of the ggplot2 package and you do not have to load the ggplot2 package seperately. Because the tidyverse consists of multiple packages, it may take a little while before everything is installed so be patient! For more information on tidyverse, have a look at https://www.tidyverse.org/. If your installation was successful, you can now load the tidyverse as follows: # load the tidyverse library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ tibble 3.0.4 ✓ dplyr 1.0.3 ## ✓ tidyr 1.1.2 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.0 ## ✓ purrr 0.3.4 ## ── Conflicts ────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Figure 4.3: Loading the tidyverse. Note After loading the tidyverse, you may get a short information messages to inform you which packages are attached to your R session and whether there are any conflicting functions. This simply means that there are functions that are named the same across the packages that you have loaded. For instance, when you load the tidyverse in a fresh R session, the tidyverse will tell you that two functions from the dplyr package (which is an integral part of the tidyverse package) mask the functionality of two functions of the stats package (which is part of base R). This simply means that if you now type in filter() you will get the dplyr functionality and not the functionality of the stats. This is very important information as both these functions do something completely different! You can still use the filter() function from the stats package but then you have to explicitly tell R that you want to use the function called filter() within the stats package: stats::filter(). Now that we have loaded the tidyverse we can continue with our data preparation. We will start by reading in the csv file that we created earlier, however, we will use the function read_csv() from the tidyverse instead of the function read.csv() from base R. The function read_csv returns a so-called tibble. Tibbles are data frames, but they tweak some older behaviours to make life a little easier. # load csv file from working directory midyear &lt;- read_csv(&#39;midyear2019_v2.csv&#39;) # inspect midyear ## # A tibble: 7,201 x 7 ## msoa_code msoa_name lad19_code lad19_name lad20_code lad20_name pop19 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E02002483 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 10 2… ## 2 E02002484 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 10 4… ## 3 E02002485 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 8 185 ## 4 E02002487 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 5 277 ## 5 E02002488 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 5 848 ## 6 E02002489 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 7 730 ## 7 E02002490 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 6 214 ## 8 E02002491 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 6 454 ## 9 E02002492 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 6 887 ## 10 E02002493 Hartlepool … E06000001 Hartlepool E06000001 Hartlepool 6 702 ## # … with 7,191 more rows Questions Do you notice a difference between how base R prints a data frame and how a tibble gets printed? Let’s have a better look at our data particularly the data types. We can can do this through the str() function: # inspect str(midyear) ## tibble [7,201 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ msoa_code : chr [1:7201] &quot;E02002483&quot; &quot;E02002484&quot; &quot;E02002485&quot; &quot;E02002487&quot; ... ## $ msoa_name : chr [1:7201] &quot;Hartlepool 001&quot; &quot;Hartlepool 002&quot; &quot;Hartlepool 003&quot; &quot;Hartlepool 005&quot; ... ## $ lad19_code: chr [1:7201] &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; ... ## $ lad19_name: chr [1:7201] &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; ... ## $ lad20_code: chr [1:7201] &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; ... ## $ lad20_name: chr [1:7201] &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; ... ## $ pop19 : chr [1:7201] &quot;10 261&quot; &quot;10 449&quot; &quot;8 185&quot; &quot;5 277&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. msoa_code = col_character(), ## .. msoa_name = col_character(), ## .. lad19_code = col_character(), ## .. lad19_name = col_character(), ## .. lad20_code = col_character(), ## .. lad20_name = col_character(), ## .. pop19 = col_character() ## .. ) The output of the str() function tells us that every column in our data frame (tibble) is of type “character”, which comes down to a variable that contains textual data. What is interesting, obviously, is that also our pop19 variable is considered a character variable. The reason for this is that in the original data white space is used as thousands separator (i.e. 11 000 instead of 11000 or 11,000). Does it matter? Well, let’s try to calculate the mean and median of our pop19 variable: # mean mean(midyear$pop19) ## Warning in mean.default(midyear$pop19): argument is not numeric or logical: ## returning NA ## [1] NA # median median(midyear$pop19) ## [1] &quot;7 251&quot; Note Depending on computer settings and the version of Microsoft Excel or spreadsheet software that you use, in some case you could get a numeric variable (e.g. double) instead of a character variable for your pop19 variable. If so: you are lucky and do not need to undertake the steps below to turn this character column into a numeric column. (This will also mean that at this stage your results will differ from the results shown here.) Just continue with the tutorial by carefully reading through the steps that you would have needed to take if indeed your results would have been the same as shown here. As you can see, this is not working perfectly for the simple fact that the the mean() function requires a numeric variable as its input! The median() does return a value, however, this is not per se the median that we are interested in as the sorting of the data is now done alphabetically: see for your self what happens when using the sort() function on the pop19 variable. Fortunately, there are some functions in the dplyr package, which is part of the tidyverse, that will help us further cleaning and preparing our data. Some of the most important and useful functions are: Package Function Use to dplyr select select columns dplyr filter select rows dplyr mutate transform or recode variables dplyr summarise summarise data dplyr group by group data into subgroups for further processing Note Remember that when you encounter a function in a piece of R code that you have not seen before and you are wondering what it does that you can get access the documentation through ?name_of_function, e.g. ?mutate. For almost any R package, the documentation contains a list of arguments that the function takes, in which format the functions expects these arguments, as well as a set of usage examples. Let’s have a look at two of the dplyr functions: select() and filter(). # select columns with the select function # note that within dplyr we not use quotation marks to refer to columns midyear_sel &lt;- select(midyear,msoa_code,msoa_name,lad20_code,lad20_name,pop19) # inspect midyear_sel ## # A tibble: 7,201 x 5 ## msoa_code msoa_name lad20_code lad20_name pop19 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E02002483 Hartlepool 001 E06000001 Hartlepool 10 261 ## 2 E02002484 Hartlepool 002 E06000001 Hartlepool 10 449 ## 3 E02002485 Hartlepool 003 E06000001 Hartlepool 8 185 ## 4 E02002487 Hartlepool 005 E06000001 Hartlepool 5 277 ## 5 E02002488 Hartlepool 006 E06000001 Hartlepool 5 848 ## 6 E02002489 Hartlepool 007 E06000001 Hartlepool 7 730 ## 7 E02002490 Hartlepool 008 E06000001 Hartlepool 6 214 ## 8 E02002491 Hartlepool 009 E06000001 Hartlepool 6 454 ## 9 E02002492 Hartlepool 010 E06000001 Hartlepool 6 887 ## 10 E02002493 Hartlepool 011 E06000001 Hartlepool 6 702 ## # … with 7,191 more rows # filter rows with the filter function # note that within dplyr we not use quotation marks to refer to columns midyear_fil &lt;- filter(midyear,lad20_name==&#39;Leeds&#39;) # inspect midyear_fil ## # A tibble: 107 x 7 ## msoa_code msoa_name lad19_code lad19_name lad20_code lad20_name pop19 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E02002330 Leeds 001 E08000035 Leeds E08000035 Leeds 6 572 ## 2 E02002331 Leeds 002 E08000035 Leeds E08000035 Leeds 7 029 ## 3 E02002332 Leeds 003 E08000035 Leeds E08000035 Leeds 6 143 ## 4 E02002333 Leeds 004 E08000035 Leeds E08000035 Leeds 7 637 ## 5 E02002334 Leeds 005 E08000035 Leeds E08000035 Leeds 7 110 ## 6 E02002335 Leeds 006 E08000035 Leeds E08000035 Leeds 7 500 ## 7 E02002336 Leeds 007 E08000035 Leeds E08000035 Leeds 6 596 ## 8 E02002337 Leeds 008 E08000035 Leeds E08000035 Leeds 7 388 ## 9 E02002338 Leeds 009 E08000035 Leeds E08000035 Leeds 6 817 ## 10 E02002339 Leeds 010 E08000035 Leeds E08000035 Leeds 5 351 ## # … with 97 more rows Questions How can we get the same data frame with selected columns (midyear_sel) using the base R syntax we have been using in previous weeks? How can we get the same data frame with filtered rows (midyear_fil) using the base R syntax we have been using in previous weeks? With the mutate() function we can easily create new columns, so let’s try this function to see if we can create a new variable that contains all the data from pop19 in a numeric format. # create a new variable named pop19_no space # by replacing all white space with nothing using the &quot;str_replace_all&quot; function midyear &lt;- mutate(midyear, pop19_nospace=str_replace_all(pop19, pattern=&#39; &#39;, repl=&#39;&#39;)) # inspect midyear ## # A tibble: 7,201 x 8 ## msoa_code msoa_name lad19_code lad19_name lad20_code lad20_name pop19 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E02002483 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 10 2… ## 2 E02002484 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 10 4… ## 3 E02002485 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 8 185 ## 4 E02002487 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 5 277 ## 5 E02002488 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 5 848 ## 6 E02002489 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 7 730 ## 7 E02002490 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 214 ## 8 E02002491 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 454 ## 9 E02002492 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 887 ## 10 E02002493 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 702 ## # … with 7,191 more rows, and 1 more variable: pop19_nospace &lt;chr&gt; # create a new variable named pop19_numeric # by transorming the pop19_nospace variable using the &quot;as.numeric&quot; function midyear &lt;- mutate(midyear,pop19_numeric=as.numeric(pop19_nospace)) # inspect midyear ## # A tibble: 7,201 x 9 ## msoa_code msoa_name lad19_code lad19_name lad20_code lad20_name pop19 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E02002483 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 10 2… ## 2 E02002484 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 10 4… ## 3 E02002485 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 8 185 ## 4 E02002487 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 5 277 ## 5 E02002488 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 5 848 ## 6 E02002489 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 7 730 ## 7 E02002490 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 214 ## 8 E02002491 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 454 ## 9 E02002492 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 887 ## 10 E02002493 Hartlepo… E06000001 Hartlepool E06000001 Hartlepool 6 702 ## # … with 7,191 more rows, and 2 more variables: pop19_nospace &lt;chr&gt;, ## # pop19_numeric &lt;dbl&gt; # inspect str(midyear) ## tibble [7,201 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ msoa_code : chr [1:7201] &quot;E02002483&quot; &quot;E02002484&quot; &quot;E02002485&quot; &quot;E02002487&quot; ... ## $ msoa_name : chr [1:7201] &quot;Hartlepool 001&quot; &quot;Hartlepool 002&quot; &quot;Hartlepool 003&quot; &quot;Hartlepool 005&quot; ... ## $ lad19_code : chr [1:7201] &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; ... ## $ lad19_name : chr [1:7201] &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; ... ## $ lad20_code : chr [1:7201] &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; &quot;E06000001&quot; ... ## $ lad20_name : chr [1:7201] &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; &quot;Hartlepool&quot; ... ## $ pop19 : chr [1:7201] &quot;10 261&quot; &quot;10 449&quot; &quot;8 185&quot; &quot;5 277&quot; ... ## $ pop19_nospace: chr [1:7201] &quot;10261&quot; &quot;10449&quot; &quot;8185&quot; &quot;5277&quot; ... ## $ pop19_numeric: num [1:7201] 10261 10449 8185 5277 5848 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. msoa_code = col_character(), ## .. msoa_name = col_character(), ## .. lad19_code = col_character(), ## .. lad19_name = col_character(), ## .. lad20_code = col_character(), ## .. lad20_name = col_character(), ## .. pop19 = col_character() ## .. ) Note the information for pop19_numeric: str indicates that the column is now of type num (i.e. numeric). This is much better. We can now try to calculate the median and the mean again: # calculate the mean of the pop19_numeric variable mean(midyear$pop19_numeric) ## [1] 8254.387 # calculate the median of the pop19_numeric variable median(midyear$pop19_numeric) ## [1] 7955 Everything seems to be working fine now and our data is now finally ready for analysis, so it is probably wise to save’s save it. # write to new csv write.csv(midyear, &#39;midyear2019_clean.csv&#39;, row.names=FALSE) Recap In this section you have learnt how to: Transform your data frame to a tibble. Use some of the functionality of the tidyverse to prepare your data set and make it suitable for analysis. 4.4 Seminar Please find the seminar task and seminar questions for this week’s seminar below. Note Please make sure that you have executed the seminar task and have answered the seminar questions before the seminar! Seminar task Of course, we did not go through all the trouble of downloading and preparing this file without using it. Use the cleaned version of the midyear data set that we just created to: Create a new object / data set that only contains data for the Local Authority District (2020 boundaries) of Manchester. Create a new object / data set that only contains data for the Local Authority District (2020 boundaries) of Birmingham. For both new objects: Calculate the mean, median, and standard deviation of the pop19_numeric variable. Create a boxplot of the pop19_numeric variable using the ggplot2 package. Create a histogram of the pop19_numeric variable using the ggplot2 package. Select a bin width that you think is appropriate. Seminar questions Compare the results of the descriptive statistics you have calculated for your Birmingham object / data set with the results of the descriptive statistics you have calculated for you Manchester data set. What do these descriptive statistics tell you? Why did you select the bin width that you used for creating your histograms? Compare the histograms that you created for your Birmingham object / data set and the Manchester data set, what can you tell about the population distribution of both Local Authority Districts? Additional tasks If you found these assignments and questions relatively easy and want an assignment that is a little more realistic, try to do the following: Download the mid-year population estimates for 2018 to your computer (Mid-2018: SAPE21DT15 (unformatted)). Make sure that you download the file with exactly this name: it is listed under the “supporting files you may find useful” heading. Prepare a csv file of the first three columns of the Mid-2018 Perons tab and import into R. Give the columns the following names: msoa_code, msoa_name, pop18. Take the necessary steps in R to make sure that all numeric variables are also recognised by R as numeric variables. Join the 2018 and 2019 midyear population data set by using the left join() function from the tidyverse() package, e.g. something like: midyear &lt;- left_join(midyear2018, midyear2019, by=c('msoa_code'='msoa_code'). Calculate the population change between 2018 and 2019. Create a histogram of the population change. Which MSOA has the largest decline in population between 2018 and 2019? Which MSOA had the largest increase in population between 2018 and 2019? Seminar link Seminars for all groups take place on Thursday morning. You can find the Zoom link to your seminar group on Moodle. 4.5 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "]
]
